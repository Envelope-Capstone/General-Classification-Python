{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-d8abe1bd5306>:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_clean.loc[:,'Description'] = df_clean.Description.str.replace('[^a-zA-Z]', ' ')\n",
      "d:\\gcu\\spring_2021\\capstone_2\\general_classification_model\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "<ipython-input-3-d8abe1bd5306>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['Description'] = df_clean['Description'].str.lower()\n"
     ]
    },
    {
     "data": {
      "text/plain": "array(['Merchandise', 'Restaurants', 'Restaurants', 'Merchandise',\n       'Restaurants', 'Restaurants', 'Restaurants', 'Services',\n       'Restaurants', 'Restaurants', 'Supermarkets', 'Restaurants',\n       'Merchandise', 'Restaurants', 'Restaurants', 'Education',\n       'Restaurants', 'Gasoline', 'Supermarkets', 'Restaurants',\n       'Gasoline', 'Restaurants', 'Supermarkets', 'Gasoline', 'Education',\n       'Restaurants', 'Supermarkets', 'Restaurants', 'Gasoline',\n       'Restaurants', 'Restaurants', 'Travel/ Entertainment',\n       'Restaurants', 'Restaurants', 'Department Stores', 'Gasoline',\n       'Supermarkets', 'Restaurants', 'Merchandise', 'Restaurants',\n       'Restaurants', 'Restaurants', 'Restaurants', 'Restaurants',\n       'Merchandise', 'Supermarkets', 'Gasoline', 'Supermarkets',\n       'Restaurants', 'Restaurants', 'Restaurants', 'Merchandise',\n       'Gasoline', 'Merchandise', 'Travel/ Entertainment', 'Supermarkets',\n       'Merchandise', 'Department Stores', 'Travel/ Entertainment',\n       'Education', 'Merchandise', 'Merchandise', 'Travel/ Entertainment',\n       'Services', 'Restaurants', 'Merchandise', 'Restaurants',\n       'Merchandise'], dtype=object)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.9117647058823529"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import sklearn.svm as svm\n",
    "import numpy as np\n",
    "import nltk.tokenize as tk\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import CountVectorizer # allows us to encode text data for ML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split # used to split data in to test and validation sets\n",
    "from sklearn.metrics import accuracy_score # calculates accuracy of our model\n",
    "from nltk.stem import WordNetLemmatizer # word net of english language used for lemmatization\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "stop_words = ['PHOENIX', 'AZ', 'AT', 'AS', 'SCOTTSDALE', 'CITUT', 'NY']\n",
    "\n",
    "\n",
    "def import_data():\n",
    "    df = pd.read_csv('disc_transactions.CSV')\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "Clean data by removing any non Alpha characters and\n",
    "Only keeping transactions that are greater than 0. These\n",
    "represent purchases. Transactions less than 0 represent\n",
    "payments to the credit card company\n",
    "\"\"\"\n",
    "def clean_data(df):\n",
    "    df_clean = df.loc[df['Amount'] > 0]\n",
    "    df_clean.loc[:,'Description'] = df_clean.Description.str.replace('[^a-zA-Z]', ' ')\n",
    "    df_clean['Description'] = df_clean['Description'].str.lower()\n",
    "    return df_clean\n",
    "\n",
    "\"\"\"\n",
    "Encode description data using bag of words approach\n",
    "Each word in the text will now become a feature, increasing our feature count significantly\n",
    "\"\"\"\n",
    "def encode_data(X):\n",
    "    count_vec = CountVectorizer(stop_words=stop_words)\n",
    "    x_encoded = count_vec.fit_transform(X.Description).toarray()\n",
    "    encode_df = pd.DataFrame(x_encoded)\n",
    "    return encode_df\n",
    "\n",
    "def encode_data_tfid(X):\n",
    "    tfid = TfidfVectorizer(stop_words='english')\n",
    "    x_encoded = tfid.fit_transform(X.Description).toarray()\n",
    "    encoded_df = pd.DataFrame(x_encoded)\n",
    "    return encoded_df\n",
    "\n",
    "\"\"\" Split data into predictor variables and target variables \"\"\"\n",
    "def split_input_output(data):\n",
    "    X = data[['Description', 'Amount']]\n",
    "    y = data['Category']\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Lemmatize the words in the description\n",
    "\"\"\"\n",
    "def lemm_x(X):\n",
    "    lemm = WordNetLemmatizer()\n",
    "    tokenize = tk.WhitespaceTokenizer()\n",
    "    for i, r in X.iterrows():\n",
    "        desc = r['Description']\n",
    "        r['Description'] = [lemm.lemmatize(w) for w in tokenize.tokenize(desc)]\n",
    "    return X\n",
    "\n",
    "df = import_data()\n",
    "\n",
    "df_clean = clean_data(df)\n",
    "df_clean = df_clean.reset_index()\n",
    "X, y = split_input_output(df_clean)\n",
    "y = y.reset_index()\n",
    "X_encoded = encode_data_tfid(X)\n",
    "\n",
    "\"\"\"\n",
    "Split the data into train and test sets\n",
    "We are using a 30/70 split.\n",
    "33.33% of data will be training\n",
    "67% will be testing data\n",
    "\"\"\"\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.33)\n",
    "\n",
    "# create the model\n",
    "transaction_classifier = svm.SVC(kernel='rbf', decision_function_shape='ovr', C=5, gamma='scale')\n",
    "# fit the model\n",
    "transaction_classifier.fit(x_train, y_train['Category'])\n",
    "\n",
    "# run standard prediction\n",
    "transaction_prediction = transaction_classifier.predict(x_test)\n",
    "display(transaction_prediction)\n",
    "# print the accuracy of the model\n",
    "accuracy_score(y_test['Category'], transaction_prediction)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}